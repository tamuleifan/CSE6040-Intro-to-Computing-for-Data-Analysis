{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ec8cf1650bc52f8313832f3d3611786b",
     "grade": false,
     "grade_id": "cell-ca9366ee8c91d9c6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Important note!** Before you turn in this lab notebook, make sure everything runs as expected:\n",
    "\n",
    "- First, **restart the kernel** -- in the menubar, select Kernel$\\rightarrow$Restart.\n",
    "- Then **run all cells** -- in the menubar, select Cell$\\rightarrow$Run All.\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigenfaces\n",
    "\n",
    "This optional assignment is an application of principal components analysis (PCA) and k-means to the analysis of \"familiar faces.\" You'll also create a simple interactive visualization for exploring this dataset.\n",
    "\n",
    "You'll need a bunch of modules, so let's load those first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some standard modules\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Modules for loading and transforming images\n",
    "\n",
    "from PIL import Image\n",
    "import base64\n",
    "from io import BytesIO\n",
    "\n",
    "def to_base64(png):\n",
    "    return \"data:image/png;base64,\" + base64.b64encode(png).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For creating an interactive visualization\n",
    "\n",
    "import bokeh\n",
    "from bokeh.io import output_notebook\n",
    "output_notebook ()\n",
    "print (\"Bokeh version:\", bokeh.__version__)\n",
    "\n",
    "from bokeh.palettes import brewer\n",
    "\n",
    "def make_color_map (values):\n",
    "    \"\"\"Given a collection of discrete values, generate a color map.\"\"\"\n",
    "    unique_values = np.unique (values) # values must be discrete\n",
    "    num_unique_values = len (unique_values)\n",
    "    min_palette_size = min (brewer['Set1'].keys ())\n",
    "    max_palette_size = max (brewer['Set1'].keys ())\n",
    "    assert num_unique_values <= max_palette_size\n",
    "    palette = brewer['Set1'][max (min_palette_size, num_unique_values)]\n",
    "    color_map = dict (zip (unique_values, palette))\n",
    "    return color_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This cell defines a function to make an interactive scatter plot of thumbnail images.\n",
    "\n",
    "## http://bokeh.pydata.org/en/latest/docs/user_guide/tools.html#userguide-tools-inspectors\n",
    "from bokeh.io import show\n",
    "from bokeh.plotting import figure, ColumnDataSource\n",
    "from bokeh.models import PanTool, BoxZoomTool, HoverTool, CrosshairTool, ResetTool\n",
    "\n",
    "def make_scatter2d_images(x, y, names=None, image_files=None, clustering=None):\n",
    "    source_data = dict(x=x, y=y)\n",
    "    if names is not None:\n",
    "        source_data[\"desc\"] = names\n",
    "        tooltips_desc = \"\"\"<span style=\"font-size: 17px; font-weight: bold;\">@desc</span>\"\"\"\n",
    "    else:\n",
    "        tooltips_desc = \"\"\n",
    "        \n",
    "    if image_files is not None:\n",
    "        source_data[\"imgs\"] = image_files\n",
    "        tooltips_images = \"\"\"\n",
    "            <div>\n",
    "                <img\n",
    "                    src=\"@imgs\" height=\"42\" alt=\"@imgs\" width=\"42\"\n",
    "                    style=\"float: left; margin: 0px 15px 15px 0px;\"\n",
    "                    border=\"2\"\n",
    "                ></img>\n",
    "            </div>\n",
    "        \"\"\"\n",
    "    else:\n",
    "        tooltips_images = \"\"\n",
    "        \n",
    "    if clustering is not None:\n",
    "        color_map = make_color_map(clustering)\n",
    "        cluster_colors = [color_map[c] for c in clustering]\n",
    "        source_data['cluster_color'] = cluster_colors\n",
    "\n",
    "    source = ColumnDataSource(data=source_data)\n",
    "    hover = HoverTool(tooltips=\"\"\"\n",
    "        <div>\n",
    "            {}\n",
    "            <div>\n",
    "                {}\n",
    "                <span style=\"font-size: 15px; color: #966;\">[$index]</span>\n",
    "            </div>\n",
    "            <div>\n",
    "                <span style=\"font-size: 15px;\">Location</span>\n",
    "                <span style=\"font-size: 10px; color: #696;\">($x, $y)</span>\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\".format(tooltips_images, tooltips_desc))\n",
    "\n",
    "    p = figure(width=600, height=600)\n",
    "    for t in [PanTool(), BoxZoomTool(), hover, CrosshairTool(), ResetTool()]:\n",
    "        p.add_tools(t)\n",
    "    \n",
    "    if clustering is not None:\n",
    "        p.circle(x='x', y='y',\n",
    "                 fill_color='cluster_color',\n",
    "                 line_color='cluster_color',\n",
    "                 size=5, source=source)\n",
    "    else:\n",
    "        p.circle(x='x', y='y', size=5, source=source)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap: Solving the PCA problem\n",
    "\n",
    "Recall the basic algorithm to compute a PCA and the interactive visual demo of which appears at http://setosa.io/ev/principal-component-analysis/.\n",
    "\n",
    "You are given a set of $m-1$ data points or observations, $X \\equiv (\\hat{x}_0, \\hat{x}_1, \\cdots, \\hat{x}_{m-1})^T$. Each observation consists of $d$ measured predictors, which we represent by the $d$-dimensional vector $x_i \\in \\mathbb{R}^d$. You wish to find a $k$-dimensional representation of these points, where $k \\leq s \\equiv \\min{m, d}$. To do so, you run the PCA procedure, which identifies a $k$-dimensional subspace in terms of $k$ orthogonal vectors (\"axes\"); these vectors are the _principal components_.\n",
    "\n",
    "1. If the data are not centered, transform them accordingly. In particular, ensure that their mean is 0, i.e., $\\displaystyle \\frac{1}{m} \\sum_{i=0}^{m-1} \\hat{x}_i = 0$.\n",
    "2. Compute the $k$-truncated SVD, $X \\approx U_k \\Sigma_k V_k^T$. The truncated SVD is just the subset of singular vectors corresponding to the largest $k$ singular values.\n",
    "3. Choose $v_0, v_1, \\ldots, v_{k-1}$ as the principal components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset: Some familiar faces\n",
    "\n",
    "The data set for this notebook is a bunch of images of people's faces. These are preloaded for those of you on either the Vocareum or Azure Notebooks platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import hashlib\n",
    "import io\n",
    "\n",
    "def on_vocareum():\n",
    "    return os.path.exists('.voc')\n",
    "\n",
    "def on_azure():\n",
    "    return 'AZURE_NOTEBOOKS_VMVERSION' in os.environ\n",
    "\n",
    "def on_vuduc_box():\n",
    "    return os.uname().nodename in ['daffy4.local', 'insomnia']\n",
    "    \n",
    "if on_vocareum():\n",
    "#    DATA_PATH, IMAGE_EXT = \"../resource/lib/publicdata/lfwcrop_grey/faces/\", \"pgm\"\n",
    "#    DATA_PATH, IMAGE_EXT = \"../resource/lib/publicdata/att_faces/\", \"pgm\"\n",
    "    DATA_PATH, IMAGE_EXT = \"../resource/lib/publicdata/mit_faces/\", \"png\"\n",
    "elif on_azure() or on_vuduc_box():\n",
    "#    DATA_PATH, IMAGE_EXT = \"peeps/\", \"png\"\n",
    "    DATA_PATH, IMAGE_EXT = \"peeps_all/\", \"tiff\"\n",
    "else:\n",
    "    print(\"\"\"\n",
    "*** Unrecognized platform ***\n",
    "\n",
    "You will need to manually download a faces dataset and modify\n",
    "this code cell to point to it by setting the `DATA_PATH` and\n",
    "`IMAGE_EXT` variables, below.\n",
    "\n",
    "Some options include:\n",
    "\n",
    "* The MIT Faces Recognition Project database:\n",
    "  http://courses.media.mit.edu/2004fall/mas622j/04.projects/faces/\n",
    "  \n",
    "* The AT&T Faces database, which has images in PGM format ('pgm' extensions):\n",
    "  http://www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.html\n",
    "  \n",
    "* The LFWcrop database, which has images in PGM format ('pgm' extensions):\n",
    "  http://conradsanderson.id.au/lfwcrop/\n",
    "    \"\"\")\n",
    "    DATA_PATH = None  # Path to image dataset\n",
    "    IMAGE_EXT = None  # Image file extension\n",
    "\n",
    "assert os.path.exists(DATA_PATH), \"Where are the images?\"\n",
    "print(\"Will look for images having a '.{}' extension in '{}'.\".format(IMAGE_EXT, DATA_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view these images, our standard procedure will be to convert them to grayscale first and then maintain them in 2-D Numpy arrays. We will use the following helper functions for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def im2gnp(image):\n",
    "    \"\"\"Converts a PIL image into an image stored as a 2-D Numpy array in grayscale.\"\"\"\n",
    "    return np.array(image.convert ('L'))\n",
    "\n",
    "def gnp2im(image_np):\n",
    "    \"\"\"Converts an image stored as a 2-D grayscale Numpy array into a PIL image.\"\"\"\n",
    "    return Image.fromarray(image_np.astype(np.uint8), mode='L')\n",
    "\n",
    "def imshow_gray(im, ax=None):\n",
    "    if ax is None:\n",
    "        f = plt.figure()\n",
    "        ax = plt.axes()\n",
    "    ax.imshow(im,\n",
    "              interpolation='nearest',\n",
    "              cmap=plt.get_cmap('gray'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's load all the images as grayscale into a list of Numpy arrays, `original_images`, along with an array `image_names` to hold a name for each image. (The names are extracted from the image filename.)\n",
    "\n",
    "The following two code cells proceed in two steps. The first gathers a list of all valid image filenames. The second loads them. If there are \"too many\" images, defined by a threshold that you can change if you are willing to wait longer, the second cell will also randomly select a subset to load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Collect list of valid image filenames\n",
    "image_file_list = []\n",
    "image_name_list = {}\n",
    "for base, dirs, files in os.walk(DATA_PATH):\n",
    "    for filename in files:\n",
    "        name_ext = re.match (r'^(.*)\\.{}$'.format(IMAGE_EXT), filename)\n",
    "        if name_ext:\n",
    "            filepath = os.path.join(base, filename)\n",
    "            image_file_list.append(filepath)\n",
    "            image_name_list[filepath] = name_ext.groups(0)[0]\n",
    "print(\"Found {} images in total.\".format(len(image_file_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load up to `MAX_IMAGES` of the available images\n",
    "MAX_IMAGES = 500\n",
    "\n",
    "if len(image_file_list) > MAX_IMAGES:\n",
    "    images_to_load = np.random.choice(image_file_list, size=MAX_IMAGES, replace=False)\n",
    "else:\n",
    "    images_to_load = image_file_list\n",
    "\n",
    "original_images = []\n",
    "image_names = []\n",
    "for filepath in images_to_load:\n",
    "    try:\n",
    "        im = im2gnp(Image.open(filepath, 'r'))\n",
    "        key = image_name_list[filepath]\n",
    "        original_images.append(im)\n",
    "        image_names.append(key)\n",
    "    except OSError:\n",
    "        print(\"WARNING: Could not recognize or open '{}'...\".format(filepath))\n",
    "        pass\n",
    "            \n",
    "print(\"Loaded\", len(original_images), \"images.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the images\n",
    "\n",
    "To apply PCA, we'll want to preprocess the images in various ways.\n",
    "\n",
    "To begin with, it's possible that that the images come in all shapes and sizes. The following code will figure out what is the largest height and width that are within the bounds of all the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min_rows, min_cols = sys.maxsize, sys.maxsize\n",
    "max_rows, max_cols = 0, 0\n",
    "for (i, image) in enumerate(original_images):\n",
    "    r, c = image.shape[0], image.shape[1]    \n",
    "    min_rows = min(min_rows, r)\n",
    "    max_rows = max(max_rows, r)\n",
    "    min_cols = min(min_cols, c)\n",
    "    max_cols = max(max_cols, c)\n",
    "    \n",
    "print(\"\\n==> Least common image size:\", min_rows, \"x\", min_cols, \"pixels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 0** (2 points). Suppose the least common image size is $r_0 \\times c_0$ pixels is the smallest dimension. Crop each $r \\times c$ image so that it is $r_0 \\times c_0$ in size. If $r > r_0$, then crop out any extra rows on the **bottom** of the image; and if $c > c_0$, then center the columns of the image. Store the output images in a **3-D** Numpy array called `images[:, :, :]`, where `images[k, :, :]` is the `k`-th image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "5992b05c09128496a83258bbf76f3dbf",
     "grade": false,
     "grade_id": "recenter",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def recenter(image, min_rows, min_cols):\n",
    "    r, c = image.shape\n",
    "    \n",
    "    # Compute four variables, `top`, `left`, `bot`,\n",
    "    # and `right` so that the `return` statement\n",
    "    # returns the recentered image.\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return image[top:bot, left:right]\n",
    "\n",
    "# Quick test\n",
    "image0 = original_images[0]\n",
    "\n",
    "print(\"{} -- Recentering: Before = {} x {} pixels; after = {} x {} pixels.\".format(image_names[0],\n",
    "                                                                                   image0.shape[0],\n",
    "                                                                                   image0.shape[1],\n",
    "                                                                                   min_rows, min_cols))\n",
    "image0_recentered = recenter(image0, min_rows, min_cols)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "imshow_gray(image0, ax=axs[0])\n",
    "imshow_gray(image0_recentered, ax=axs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2ec4da113419a10dda53c4f7a421702b",
     "grade": true,
     "grade_id": "recenter_test",
     "locked": true,
     "points": 2.0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Test cell: `recenter_test`\n",
    "\n",
    "# Re-center images to a common size\n",
    "images_recentered = np.zeros((len(original_images), min_rows, min_cols))\n",
    "for (k, image) in enumerate(original_images):\n",
    "    images_recentered[k, :, :] = recenter(image, min_rows, min_cols)\n",
    "    \n",
    "print(\"\\n(Passed!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aside: Generating thumbnails.** The latter part of this notebook creates an interactive visualization, for which we will need thumbnail versions of these images. The following code creates those thumbnails. It stores them as a list, `thumbnails[:]`, of Base64-encoded binary `PNG` data, which can be embedded directly into HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "thumbnails = []\n",
    "for gnp in images_recentered:\n",
    "    im = gnp2im(gnp)\n",
    "    memout = BytesIO()\n",
    "    im.save(memout, format='png')\n",
    "    thumbnails.append(to_base64(memout.getvalue()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1** (2 points). Compute an \"average\" image, taken as the elementwise (pixelwise) mean over all images. Store the result in a `min_rows` $\\times$ `min_cols` Numpy array called, `mean_image`.\n",
    "\n",
    "> The cell will display this \"average face.\" How would you describe it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "ad6f6a4bfb1ecd72b7b334d921ba655f",
     "grade": false,
     "grade_id": "mean_image",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Store your result in a variable called `mean_image`\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "    \n",
    "# Display the \"average\" face\n",
    "imshow_gray(mean_image)\n",
    "gnp2im(mean_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2** (2 points). Recall that PCA requires centered points. Let's do that by subtracting the mean image from every image. Use the recentered images computed in one of the above tests (`images_recentered`) and store the result in a new array, `images`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "69c8ac020dc135c2c40e8cf55e3e75cf",
     "grade": false,
     "grade_id": "sub_mean",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "f, axs = plt.subplots(1, 4, figsize=(10, 40))\n",
    "imshow_gray(images[0, :, :] + mean_image, ax=axs[0])\n",
    "imshow_gray(images[0, :, :], ax=axs[1]) # Compare this to the original.\n",
    "imshow_gray(images[-1, :, :] + mean_image, ax=axs[2])\n",
    "imshow_gray(images[-1, :, :], ax=axs[3]) # Compare this to the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c3d6214cbd93e8cf2b249ee8894b0931",
     "grade": true,
     "grade_id": "sub_mean_test",
     "locked": true,
     "points": 2.0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Test cell: `sub_mean_test`\n",
    "\n",
    "max_abs_sum = np.max(np.abs((np.sum(images, axis=0))))\n",
    "max_abs_sum_bound = np.finfo(float).eps * (len(images)**2) * np.max(images)\n",
    "print(max_abs_sum, \"<=\", max_abs_sum_bound, \"?\")\n",
    "assert max_abs_sum <= max_abs_sum_bound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From image set to a data matrix and back again\n",
    "\n",
    "For PCA, you need a data matrix. Here is some code to convert our 3-D array of images into a 2-D data matrix, where we \"flatten\" each image into a 1-D vector by a simple `reshape()` operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create m x d data matrix\n",
    "m = len(images)\n",
    "d = min_rows * min_cols\n",
    "X = np.reshape(images, (m, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To get back to an image, just reshape it again\n",
    "imshow_gray(np.reshape(X[int(len(X)/2), :], (min_rows, min_cols)))\n",
    "print(image_names[int(len(X)/2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3** (2 points). Compute the SVD of `X`. Store the result in three arrays, `U`, `Sigma`, and `VT`, where `U` holds $U$, `Sigma` holds just the diagonal entries of $\\Sigma$, and `VT` holds $V^T$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "85f30e97890e7c5271ef1cfd8931a34b",
     "grade": false,
     "grade_id": "svd",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "fefd5a7da1c0abce420ddc17ad03533c",
     "grade": true,
     "grade_id": "svd_test",
     "locked": true,
     "points": 2.0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Sanity check on dimensions\n",
    "print(\"X:\", X.shape)\n",
    "print(\"U:\", U.shape)\n",
    "print(\"Sigma:\", Sigma.shape)\n",
    "print(\"V^T:\", VT.shape)\n",
    "\n",
    "assert X.shape == (len(images), min_rows * min_cols)\n",
    "\n",
    "s = min(X.shape)\n",
    "assert U.shape == (len(images), s)\n",
    "assert Sigma.shape == (s,)\n",
    "assert VT.shape == (s, min_rows * min_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code inspects the singular values, i.e., the entries of $\\Sigma$ stored in `Sigma`. The plot will show the singular values as dots, plotted at each position $x=i$ for the $i$-th singular values. To give you a rough idea of how quickly the singular values decay, the plot includes a solid line showing the curve, $\\frac{\\sigma_0}{\\sqrt{i+1}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def peek_Sigma (Sigma, ret_df=False):\n",
    "    k = len (Sigma)\n",
    "    df_Sigma = pd.DataFrame()\n",
    "    df_Sigma['i'] = np.arange(k)\n",
    "    df_Sigma['sigma_i'] = Sigma\n",
    "    Sigma_sq = np.power (Sigma, 2)\n",
    "    Err_sq = np.sum(Sigma_sq) - np.cumsum(Sigma_sq)\n",
    "    Err_sq[Err_sq < 0] = 0\n",
    "    Err = np.sqrt(Err_sq)\n",
    "    Relerr = Err / (Sigma[0] + Err[0])\n",
    "    df_Sigma['sigma_i^2'] = Sigma_sq\n",
    "    df_Sigma['err_i^2'] = Err_sq\n",
    "    df_Sigma['err_i'] = Err\n",
    "    df_Sigma['relerr_i'] = Relerr\n",
    "    print(\"Singular values:\")\n",
    "    display(df_Sigma.head())\n",
    "    print(\"  ...\")\n",
    "    display(df_Sigma.tail())\n",
    "    \n",
    "    f, ax = plt.subplots (figsize=(7, 7))\n",
    "    #ax.set (yscale=\"log\")\n",
    "    sns.regplot(\"i\", \"sigma_i\", df_Sigma, ax=ax, fit_reg=False)\n",
    "    if ret_df:\n",
    "        return df_Sigma\n",
    "    \n",
    "df_Sigma = peek_Sigma(Sigma, ret_df=True)\n",
    "\n",
    "# Adds a red line to the plot: y ~ sigma_0 / sqrt(i+1)\n",
    "plt.plot(df_Sigma['i'], df_Sigma['sigma_i'][0]*np.power(df_Sigma['i']+1, -0.5),\n",
    "         color=\"red\", linewidth=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4** (ungraded). Does the spectrum of these data decay quickly or slowly? How should that affect your choice of $k$, if you are considering a $k$-truncated SVD?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e334e31b0d287a760174c01a0fceca11",
     "grade": false,
     "grade_id": "spectrum_decay",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Answer.** The question is ill-defined and the answer is relative. In this case, a reasonable argument is that the spectrum actually decays somewhat slowly. Why? If you try fitting the singular values $\\{\\sigma_i\\}$ to functions of $i$, you'll find that $\\frac{1}{\\sqrt{i+1}}$ is actually a pretty good fit. That is considered fairly slow decay; there would be significant compressibility if the curve dropped off exponentially (or at least superlinearly) instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's plot the first few principal components. From what you computed above, each right singular vector has the same number of entries as there are pixels in an image. So, we could plot them as images by reshaping them. What do they appear to capture?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f8ad469d625c32dd9057cc0bb2348f8e",
     "grade": false,
     "grade_id": "inspect_pcs",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "k_plot = 5\n",
    "fig, axs = plt.subplots(1, k_plot, figsize=(20, 60))\n",
    "for k_i in range(k_plot):\n",
    "    vector_as_image = np.reshape(np.abs(VT[k_i, :]), (min_rows, min_cols))\n",
    "    imshow_gray(vector_as_image, ax=axs[k_i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5** (2 points). Write some code to compute a new matrix `Y`, which is the original data matrix projected onto the first `num_components` principal components.\n",
    "\n",
    "> You can use the code cell below, which calls `make_scatter2d_images`, to create an interactive plot of your projection. Does it reveal any interesting groupings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "cbd3fe1049a73a139fecf9f9fb98bf1f",
     "grade": false,
     "grade_id": "Y",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "num_components = 5 # Number of principal components\n",
    "\n",
    "# Define `Y`:\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "p = make_scatter2d_images(Y[:, 0], Y[:, 1], # Try plotting different axes\n",
    "                          names=image_names,\n",
    "                          image_files=thumbnails)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a8fdfd5d6b91a29573e55debe5c761da",
     "grade": true,
     "grade_id": "Y_test",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Test cell: `Y_test`\n",
    "\n",
    "assert Y.shape == (len(X), num_components)\n",
    "print(\"\\n('Passed' -- not really checking anything...)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6** (2 points). Run $k$-means on the projected data, `Y[:m, :num_components]`, to try to identify up to `num_clusters` clusters. Store the cluster centers in an array `centers[:num_clusters, :2]` and the cluster labels in an array `clustering[:m]`.\n",
    "\n",
    "> You may use Scipy's `kmeans()` routine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "128b47af1841ff13de8f4b3d400375c2",
     "grade": false,
     "grade_id": "run_kmeans",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from scipy.cluster.vq import kmeans, vq\n",
    "\n",
    "num_clusters = 3 # Try changing this value\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "print(centers)\n",
    "\n",
    "p = make_scatter2d_images(Y[:, 0], Y[:, 1], # Try plotting different axes\n",
    "                          names=image_names,\n",
    "                          image_files=thumbnails,\n",
    "                          clustering=clustering)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f9898d4bb78e4cec4d747b070366c3a9",
     "grade": true,
     "grade_id": "run_kmeans_test",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Test cell: `run_kmeans_test`\n",
    "\n",
    "df_kcurve = pd.DataFrame (columns=['k', 'distortion']) \n",
    "for i in range(1,10):\n",
    "    _, distortion = kmeans(Y, i)\n",
    "    df_kcurve.loc[i] = [i, distortion]\n",
    "df_kcurve.plot(x=\"k\", y=\"distortion\")\n",
    "\n",
    "print(\"\\n('Passed' -- not really checking anything...)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Today's notebook uses a bunch of library modules and coding tricks; if you want to learn more, see these references.\n",
    "\n",
    "_Image manipulation_\n",
    "* Working with TIFFs: http://stackoverflow.com/questions/7569553/working-with-tiffs-import-export-in-python-using-numpy\n",
    "* Displaying PIL images inline: http://stackoverflow.com/questions/26649716/how-to-show-pil-image-in-ipython-notebook\n",
    "* Convert to grayscale: http://stackoverflow.com/questions/12201577/how-can-i-convert-an-rgb-image-into-grayscale-in-python\n",
    "\n",
    "_PCA in Python_\n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
